---
title: 'Fin Econ: Midterm Project'
author: "Hunter Giles"
date: "2022-09-27"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Sets

## Intro

The goal of this project is to generate synthetic data from two different stocks, while maintaining the marginal stock distributions and the association between the two stocks. This is an important task because stock data has a limited quantity within a given time interval. It is obvious that there are only 12 observations of monthly data per stock per year (120 for 10 years). Therefore, synthetic data can be useful to proliferate the observations. One use case for the new data is using it to build larger models that require more data such as ensemble models or neural networks.

A careful step-by-step process is necessary to create the synthetic data. First, consideration is taken when deciding two stocks that may have a relevant relationship. Amazon and Apple are both multinational technology companies. Amazon primary focus is e-commerce, but also offers video steaming, cloud services, and more. Apple focuses in computer and smart phone production, while offering cloud services, and audio and video streaming. Both companies are tech giants and therefore will likely have some relationship.

Monthly and daily data is downloaded from a creditable source, yahoo finance, for the past 10 years. This analysis uses adjusted closed stock prices to account for executive intervention in stock prices. The adjusted prices are then converted to log returns. The monthly data is taken from the first day of each month.

```{r, include=F}
library(quantmod)
library(dplyr)
library(sn)
library(MASS)
library(fGarch)
library(ks)
library(copula)
```

```{r, warning=F, message=F, results=F}
getSymbols("AAPL;AMZN",
           from = "2011/12/31",
           to = "2021/12/31",
           periodicity = "monthly")
```

```{r, warning=F, message=F}
AAPL$log.return <- log(AAPL$AAPL.Adjusted) - log(stats::lag(AAPL$AAPL.Adjusted))
AAPL <- AAPL[-1]

AMZN$log.return <- log(AMZN$AMZN.Adjusted) - log(stats::lag(AMZN$AMZN.Adjusted))
AMZN <- AMZN[-1]
```

# Marginals
The data is fitted to different marginal distributions (Normal, Skewed Normal, Student's T, and Skewed Student's T) using a log-likelihood optimization method to find optimal parameters (mean, standard deviation, degrees-of-freedom, etc). The best fitting distribution is selected by taking the minimum AIC, which in this case is Skewed Student's T for both stocks. The AICs are preferred over the BICs because this data is intended for prediction use rather than causal analysis.


```{r, include=F}
AICs <- matrix(rep(NA,8),ncol = 2)
colnames(AICs) <- c("APPL", "AMZN")
rownames(AICs) <- c("Normal", "Skewed Normal", "Student T", "Skewed Student T")
```

### APPL Fits

#### Normal Distribution

```{r, warning=F, message=F}
x1 <- AAPL$log.return
start <- c(mean(x1), sd(x1))
logLik_nd <- function(theta) {
  f <- sum(-dnorm((x1 - theta[1])/theta[2],log=T))
  return(f)
}
aapl_mle_nd <- optim(start,logLik_nd, method = "L-BFGS-B",
                     lower = c(-0.1, 0.001, 2.1),
      upper = c(0.1, 1, 20))
```

```{r, echo=F, results=T}
cat("MLE =", round(aapl_mle_nd$par, digits = 5))
AICs[1,1] <- -2*log(aapl_mle_nd$value) - 2*length(start)
```

#### Skewed Normal Distribution

```{r, warning=F, message=F}
start <- c(mean(x1), sd(x1), 1)
logLik_sknd <- function(theta) {
  f <- -sum(log(sn::dsn(x1,xi = theta[1], omega = theta[2], alpha = theta[3])))
  return(f)
}
aapl_mle_sknd <- optim(start, logLik_sknd, method = "L-BFGS-B")
```

```{r, echo=F, results=T}
cat("MLE =", round(aapl_mle_sknd$par, digits = 5))
AICs[2,1] <- -2*log(abs(aapl_mle_sknd$value)) - 2*length(start)
```

#### Student's T Distribution

```{r warning=FALSE}
#fitdistr(x1,"t")
start <- c(mean(x1), sd(x1), 5)
logLik_std <- function(theta) {
  f <- sum(-dstd(x1, mean = theta[1], sd = theta[2], nu = theta[3], log = T))
  return(f)
}
aapl_mle_std <- optim(start, logLik_std, method = "BFGS")
```

```{r, echo=F, results=T}
cat("MLE =", round(aapl_mle_std$par, digits = 5))
AICs[3,1] <- -2*log(abs(aapl_mle_std$value)) - 2*length(start)
```

#### Skewed Student's T Distribution

```{r warning=FALSE}
aapl_mle_sstd <- sstdFit(x1)
theta <- aapl_mle_sstd$estimate
aapl_fit_sstd <- sum(-dsstd(x1, mean = theta[1], sd = theta[2], nu = theta[3], xi = theta[4], log = T))
```

```{r, echo=F, results=T}
cat("MLE =", round(theta, digits = 5))
AICs[4,1] <- -2*log(abs(aapl_fit_sstd)) - 2*length(theta)
```

### AMZN Fits

#### Normal Distribution

```{r, warning=F, message=F}
x1 <- AMZN$log.return
start <- c(mean(x1), sd(x1))
logLik_nd <- function(theta) {
  f <- sum(-dnorm((x1 - theta[1])/theta[2],log=T))
  return(f)
}
amzn_mle_nd <- optim(start,logLik_nd, method = "L-BFGS-B",
                     lower = c(-0.1, 0.001, 2.1),
      upper = c(0.1, 1, 20), hessian = TRUE)
```

```{r, echo=F, results=T}
cat("MLE =", round(amzn_mle_nd$par, digits = 5))
AICs[1,2] <- -2*log(aapl_mle_nd$value) - 2*length(start)
```

#### Skewed Normal Distribution

```{r, warning=F, message=F}
start <- c(mean(x1), sd(x1), 1)
logLik_sknd <- function(theta) {
  f <- -sum(log(sn::dsn(x1,xi = theta[1], omega = theta[2], alpha = theta[3])))
  return(f)
}
amzn_mle_sknd <- optim(start, logLik_sknd, method = "L-BFGS-B")
```

```{r, echo=F, results=T}
cat("MLE =", round(amzn_mle_sknd$par, digits = 5))
# should this be absoulute value
AICs[2,2] <- -2*log(abs(amzn_mle_sknd$value)) - 2*length(start)
```

#### Student's T Distribution

```{r, warning=F, message=F}
amzn_std_fit <- fitdistr(x1,"t")
theta <- amzn_std_fit$estimate
amzn_mle_std <- sum(-dstd(x1, mean = theta[1], sd = theta[2], nu = theta[3], log = T))
```

```{r, echo=F, results=T}
cat("MLE =", round(theta, digits = 5))
AICs[3,2] <- -2*log(abs(amzn_mle_std)) - 2*length(theta)
```

#### Skewed Student's T Distribution

```{r, warning=F, message=F}
amzn_sstd_fit <- sstdFit(x1)
theta <- amzn_sstd_fit$estimate
amzn_mle_sstd <- sum(-dstd(x1, mean = theta[1], sd = theta[2], nu = theta[3], log = T))
```

```{r, echo=F, results=T}
cat("MLE =", round(theta, digits = 5))
AICs[4,2] <- -2*log(abs(amzn_mle_sstd)) - 2*length(theta)
```
#### Distribution AICs
The AICs, displayed below are calculated using the following formula:  
$$ 
AIC = -2*log[\hat{L(\theta})]-2p, \space \text{where } p \text{ is the length of } \theta
$$  

```{r, echo=FALSE, results=T}
library(htmlTable)
AICs %>% htmlTable(caption = "AIC values for each Distribution")
```

#### SSTD Summary Statistics
The optimized parameters are below:

```{r, echo=F, results=T}
all_params <- matrix(rep(NA,8),ncol = 2)
colnames(all_params) <- c("Apple", "Amazon")
rownames(all_params) <- c("mean", "sd", "df", "alpha")
all_params[,1] <- round(aapl_mle_sstd$estimate, 5)
all_params[,2] <- round(amzn_sstd_fit$estimate, 5)
all_params %>% htmlTable(caption = "Monthly Summary Statistics")
```

# Copulas
### Set Up

```{r,include=F}
AIC.copula <- matrix(rep(NA,5),ncol = 1)
colnames(AIC.copula) <- "Copula"
rownames(AIC.copula) <- c("Guassian", "Frank", "Student's T", "Gumbel", "Joe") # add Gumbel and joe because there is a positive correlation and rank correlation
```

Next, the optimized marginal parameters are used to create a copula. This is done by estimating the probability of log returns from their stocks' respective marginal CDFs (P{return \< x}). The transformation restricts the domain and creates a uniform(0,1) distribution of probabilities. Kendall's tau and correlation matrix are estimated below:

```{r, warning=F, message=F, include=F}
x.aapl <- AAPL$log.return
x.amzn <- AMZN$log.return

theta.aapl <- aapl_mle_sstd$estimate
theta.amzn <- amzn_sstd_fit$estimate
# Why is this not qsstd(psstd(blah blah))
# what is dp2cp()
```

```{r}
u1 <- psstd(x.aapl, mean = theta.aapl[1], sd = theta.aapl[2], nu = theta.aapl[3], xi = theta.aapl[4])
u2 <- psstd(x.amzn, mean = theta.amzn[1], sd = theta.amzn[2], nu = theta.amzn[3], xi = theta.amzn[4])

tau <- cor.test(as.numeric(u1),as.numeric(u2),method="kendall")$estimate

omega <- sin(tau*pi/2)
```

```{r, echo=F, results=T}
co <- matrix(rep(NA, 3),ncol=1)
colnames(co) <- c("Estimates")
rownames(co) <- c("pearson", "kendall", "omega")
co[,1] <- c(cor(AAPL$log.return, AMZN$log.return), tau, omega)
co %>% htmlTable(caption = "Stock Associations")
```

Below is the non-parametric probability density estimations for original monthly data.
```{r, echo=F, results=T}
U.hat <- data.frame(u1,u2)
names(U.hat) <- c("AAPL Returns", "AMZN Returns")
fhatU <- kde(x=U.hat,H=Hscv(x=U.hat));#nonparametric density estimation 
plot(fhatU,cont=seq(10,80,10)); #contour plots
```

### Fits
Multiple copulas are fitted (Gaussian, Frank, T-Copula, Gumbel, and Joe). Gumbel and Joe are included because Amazon and Apple have a positive correlation. The Frank copula is chosen to represent to stocks relationship because it has the lowest AIC.

#### Gaussian Copula

```{r, warning=F, message=F}
Cguas <- fitCopula(copula=normalCopula(dim=2),data=U.hat,method="ml",start=c(omega))
guas_params <- coef(Cguas)

guas_logLik <- loglikCopula(param=guas_params,u=as.matrix(U.hat),copula=normalCopula(dim=2)) 
```

```{r, include=F}
AIC.copula[1,1] <- -2*abs(guas_logLik)+2*length(guas_params)
```

#### Frank Copula

```{r, warning=F, message=F}
Cfr <- fitCopula(copula=frankCopula(dim=2),data=as.matrix(U.hat),method="ml", start=1) 
fr_params <- coef(Cfr)

fr_logLik <- loglikCopula(param=fr_params,u=as.matrix(U.hat),copula=frankCopula(dim=2)) 
```

```{r, include=F}
AIC.copula[2,1] <- -2*abs(fr_logLik)+2*length(fr_params)
```

#### T-Copula

```{r, warning=F, message=F}
Ct <- fitCopula(copula=tCopula(dim=2),data=U.hat,method="ml",start=c(omega,10)) # 10 is degrees of freedom
t_params <- coef(Ct)

t_logLik <- loglikCopula(param=t_params,u=as.matrix(U.hat),copula=tCopula(dim=2)) 
```

```{r, include=F}
AIC.copula[3,1] <- -2*t_logLik+2*length(t_params)
```

#### Gumbel Copula

```{r, warning=F, message=F}
Cgum <- fitCopula(copula=gumbelCopula(dim=2),data=U.hat,method="ml",start=1) 
gum_params <- coef(Cgum)

gum_logLik <- loglikCopula(param=gum_params,u=as.matrix(U.hat),copula=gumbelCopula(dim=2)) 
```

```{r, include=F}
AIC.copula[4,1] <- -2*gum_logLik+2*length(gum_params)
```

#### Joe Copula

```{r, warning=F, message=F}
Cjoe <- fitCopula(copula=joeCopula(dim=2),data=U.hat,method="ml",start=1)
joe_params <- coef(Cjoe)

joe_logLik <- loglikCopula(param=joe_params,u=as.matrix(U.hat),copula=joeCopula(dim=2)) 
```

```{r, include=F}
AIC.copula[5,1] <- -2*joe_logLik+2*length(joe_params)
```

#### Copula AICs
The Frank Copula is selected because it has the lowest AIC.
```{r, echo=F, results=T}
AIC.copula %>% htmlTable(caption = "Copula AICs")
```

# Simulated Data

#### Creating Synthetic Data

Synthetic data is generated using the following process. Using the rCopula() function in R's copula package, random probability values are taken from the fitted copula. The randomness is subject to the copulas distribution. These probabilities are of the stocks marginal uniform(0,1) distribution. The probabilities can then be transformed into stock log returns using the fitted Skewed Student's T quantile formula. The resulting quantities are synthetic values. Their data is formatted as two columns (one per stock) with equal lengths. The rCopula() function can produce any number of synthetic data points, but for this analysis the same number of original stock returns is chosen.

```{r, warning=F, message=F}
syn_prob <- rCopula(copula = frankCopula(param = fr_params), n = length(x.aapl))
colnames(syn_prob) <- c("AAPL", "AMZN")

syn_x.aapl <- qsstd(syn_prob[,1], mean = theta.aapl[1], sd = theta.aapl[2], nu = theta.aapl[3], xi = theta.aapl[4])
syn_x.amzn <- qsstd(syn_prob[,2], mean = theta.amzn[1], sd = theta.amzn[2], nu = theta.amzn[3], xi = theta.amzn[4])
```
```{r, include=F}
syn_x = cbind(syn_x.aapl, syn_x.amzn)
```

### Plotting Data
#### Monthly

```{r, include=F}
library(ggplot2)
library(gridExtra)
library(gdata)
```

```{r message=FALSE, warning=FALSE, results='hide'}
ggplot(data.frame(syn_prob)) +
  geom_point(mapping = aes(x=AAPL, y=AMZN)) +
  labs(title = "Synthetic Probabilities")
```

```{r, echo=F, results=F}
x <- data.frame(cbind(AAPL$log.return, AMZN$log.return))
colnames(x) <- c("AAPL", "AMZN")

syn_x <- data.frame(syn_x) 
colnames(syn_x) <- c("AAPL", "AMZN")
a <- combine(x,syn_x)
ggplot(a) +
  geom_point(mapping = aes(x=AAPL, y=AMZN, color = source)) +
  labs(title = "Monthly Original and Synthetic Returns")
```

```{r, echo=F, results='hide'}
getSymbols("AAPL;AMZN",
           from = "2011/12/31",
           to = "2021/12/31",
           periodicity = "daily")
AAPL$log.return <- log(AAPL$AAPL.Adjusted) - log(stats::lag(AAPL$AAPL.Adjusted))
AAPL <- AAPL[-1]

AMZN$log.return <- log(AMZN$AMZN.Adjusted) - log(stats::lag(AMZN$AMZN.Adjusted))
AMZN <- AMZN[-1]
stock.d <- cbind(AAPL$log.return, AMZN$log.return)
```

#### Daily

```{r,echo=F, results=T}
ggplot(stock.d) +
  geom_point(mapping = aes(x=log.return, y=log.return.1)) +
  labs(title = "Daily Original and Synthetic Returns")
```

#### Daily Summary Statistics
```{r, echo=F, results=T}
al <- matrix(rep(NA,9),ncol = 3)
colnames(al) <- c("Apple","Amazon","Combine")
rownames(al) <- c("mean", "sd", "pearson")
al[,1] <- c(mean(AAPL$log.return) %>% round(5), sd(AAPL$log.return)%>% round(5), "-")
al[,2] <- c(mean(AMZN$log.return)%>% round(5), sd(AMZN$log.return)%>% round(5), "-")
al[,3] <- c("-", "-", cor(AMZN$log.return, AAPL$log.return)%>% round(5))
al %>% htmlTable(caption = "Daily Summary Statistics")
```

# Conclusion
As predicted, Apple and Amazon have a dependent and correlated relationship, this is likely from being in the same market sector. From the scatter plots, the synthetic and original data appear to have very similar distributions. This visual evidence shows that the synthetic data is likely a good representation of the original data. The monthly synthetic and originally data distribution are different from the daily log return distributions. The average daily log returns are lower, but still positive, and the variance is much smaller. Visually, the data does appear to be more dense around the mean in the daily scatter plot.



```{r, include=F}
# s1 = sd(x$AAPL)
# s2 = sd(x$AMZN)
# u1 = mean(x$AAPL)
# u2 = mean(x$AMZN)
# r = cor(x$AAPL, x$AMZN)
# covar = r*s1*s2
# Sigma = matrix(ncol=2,nrow=2,c(s1^2,covar,covar,s2^2))
# temp = eigen(Sigma)
# SqrtSigma = temp$vectors%*%diag(sqrt(temp$values))%*%t(temp$vectors)
# XYvec = c(u1,u2) + SqrtSigma%*%rssdt(2)
# x3 = rep(NA,2000) # change value here
# y3 = rep(NA,2000) # change value here
# for(i in 1:2000){
#   XYvec = c(u1,u2) + SqrtSigma%*%rnorm(2)
#   x3[i] = XYvec[1]
#   y3[i] = XYvec[2]
# }
# 
# syn_prob <- rCopula(copula = frankCopula(param = fr_params), n = 2000) # change value
# colnames(syn_prob) <- c("AAPL", "AMZN")
# plot(syn_prob)
# syn_x.aapl <- qsstd(syn_prob[,1], mean = theta.aapl[1], sd = theta.aapl[2], nu = theta.aapl[3], xi = theta.aapl[4])
# syn_x.amzn <- qsstd(syn_prob[,2], mean = theta.amzn[1], sd = theta.amzn[2], nu = theta.amzn[3], xi = theta.amzn[4])

# syn_x = cbind(syn_x.aapl, syn_x.amzn)
# x <- data.frame(cbind(AAPL$log.return, AMZN$log.return))
# colnames(x) <- c("AAPL", "AMZN")
# 
# syn_x <- data.frame(syn_x) 
# colnames(syn_x) <- c("AAPL", "AMZN")
# b <- data.frame(cbind(x3,y3))
# colnames(b) <- c("AAPL", "AMZN")
# c <- combine(b,syn_x)
# ggplot(c) +
#   geom_point(mapping = aes(x=AAPL, y=AMZN, color=source, alpha = .5))
```
